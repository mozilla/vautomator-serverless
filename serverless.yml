
service: vautomator-serverless
frameworkVersion: ">=1.2.0 <2.0.0"

provider:
  name: aws
  runtime: python3.6
  region: us-west-2
  # To use the bucket specified, we will need permissions
  iamRoleStatements:
   - Effect: "Allow"
     Action:
       - "s3:PutObject"
       - "s3:PutObjectAcl"
     Resource: 
      Fn::Join:
        - ""
        - - Fn::GetAtt:
            - S3BucketResults
            - Arn
          - "/*"
   - Effect: "Allow"
     Action:
      - "sqs:SendMessage"
     Resource:
      Fn::GetAtt: [ SQSQueue, Arn ]
   - Effect: Allow
     Action:
      - "sqs:SendMessage"
     Resource:
      - "Fn::GetAtt":
        - ReceiverDeadLetterQueue
        - Arn
  environment:
    HTTPOBS_API_URL: 'https://http-observatory.security.mozilla.org/api/v1'
    TLSOBS_API_URL: 'https://tls-observatory.services.mozilla.com/api/v1'
    # Using Observatory list as source list for scheduled scans as it is comprehensive enough
    # This could be updated later, perhaps to another source, such as pentest-master list?
    HOST_LIST: 'https://raw.githubusercontent.com/mozilla/http-observatory-dashboard/master/httpobsdashboard/conf/sites.json'
    SQS_URL:
      Ref: SQSQueue
  apiKeys:
    - ${self:service}-api-key

# Adding some packaging information here to clean up
# and to include the nmap static library
package:
  include:
    - vendor/*
  exclude:
    - .venv/**
    - .git/**
    - __pycache__/**
    - node_modules/**

functions:
  onDemandPortScan:
    handler: handler.queue_portscan
    events:
      - http:
          path: ondemand/portscan
          method: POST
          cors: true
          private: ${self:custom.cfg.private}
  onDemandHttpObservatoryScan:
    handler: handler.queue_httpboservatory
    events:
      - http:
          path: ondemand/httpobservatory
          method: POST
          cors: true
  onDemandSshObservatoryScan:
    handler: handler.queue_sshobservatory
    events:
      - http:
          path: ondemand/sshobservatory
          method: POST
          cors: true
  onDemandTlsObservatoryScan:
    handler: handler.queue_tlsobservatory
    events:
      - http:
          path: ondemand/tlsobservatory
          method: POST
          cors: true 
  cronPortScan:
    handler: handler.queue_scheduled_portscan
    timeout: 60
    events:
      # Invoke Lambda function once a week
      # Run at 6 PM UTC every Wednesday once
      - schedule: 
          rate: cron(0 18 ? * WED *)
          # Not enabling this by default as it is intrusive in nature
          enabled: false
  cronHttpObservatoryScan:
    handler: handler.queue_scheduled_httpobservatory
    timeout: 60
    events:
      # Invoke Lambda function once a day
      # Run at 4 PM UTC every day
      - schedule: 
          rate: cron(0 16 * * ? *)
          enabled: true
  cronTlsObservatoryScan:
    handler: handler.queue_scheduled_tlsobservatory
    timeout: 60
    events:
      # Invoke Lambda function once a day
      # Run at 4 PM UTC every day
      - schedule:
          rate: cron(0 16 * * ? *)
          enabled: true
  cronSshObservatoryScan:
    handler: handler.queue_scheduled_sshobservatory
    timeout: 60
    events:
      # Invoke Lambda function once a day
      # Run at 4 PM UTC every day
      - schedule: 
          rate: cron(0 16 * * ? *)
          enabled: true
  RunScanQueue:
    handler: handler.runScanFromQ
    # Giving this function a large timeout so port scans could run
    timeout: 300
    events:
      - sqs:
          arn:
            Fn::GetAtt: [ SQSQueue, Arn ]
          batchSize: 1
  ingest:
    # Demo function, not called on an event, but manually
    handler: handler.putInQueue

plugins:
  - serverless-python-requirements
resources:
  Resources:
    S3BucketResults:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.cfg.s3BucketName}
    # Define a dead letter queue here
    ReceiverDeadLetterQueue:
      Type: "AWS::SQS::Queue"
      Properties:
        QueueName: ${self:custom.cfg.vautomatorDLQ}
        MessageRetentionPeriod: 120
    SQSQueue:
      Type: AWS::SQS::Queue
      Properties:
        QueueName: ${self:custom.cfg.vautomatorQ}
        VisibilityTimeout: 300
        MessageRetentionPeriod: 300
        # Use the dead letter queue
        RedrivePolicy:
          deadLetterTargetArn:
            "Fn::GetAtt":
              - ReceiverDeadLetterQueue
              - Arn
          maxReceiveCount: 2
custom:
  cfg:
    s3BucketName: "vautomator-results"
    vautomatorQ: "vautomator-SQS"
    vautomatorDLQ: "vautomator-DLQ"
    private: true # Change to 'false' to disable api-key authorization
  pythonRequirements:
    dockerizePip: true
